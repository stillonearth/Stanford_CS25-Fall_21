{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to mokeypatch torchtext to get this to work\n",
    "# The reason is that dated torchtext had bad dataset hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 16:41:18.328574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "import GPUtil\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from transformer.training import Batch, TrainState, run_epoch, create_dataloaders\n",
    "from transformer.transformer import make_model, greedy_decode\n",
    "from transformer.tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n"
     ]
    }
   ],
   "source": [
    "spacy_de, spacy_en = load_tokenizers()\n",
    "vocab_src, vocab_tgt = load_vocab(spacy_de, spacy_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "\n",
    "    def __init__(self, generator, criterion):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "\n",
    "    #? why would / by norm be needed and then * by norm?\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        sloss = (\n",
    "            self.criterion(\n",
    "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "            )\n",
    "            / norm\n",
    "        )\n",
    "        # 1st term is used for reporting, 2nd term is used for backprop\n",
    "        return sloss.data * norm, sloss\n",
    "    \n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = torch.zeros_like(x.data)\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        # https://yuyangyy.medium.com/understand-torch-scatter-b0fd6275331c\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        return self.criterion(x, true_dist.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for LambdaLR function\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html\n",
    "\n",
    "# This regulates learning for each step\n",
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_worker(\n",
    "    gpu,\n",
    "    ngpus_per_node,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_de,\n",
    "    spacy_en,\n",
    "    config,\n",
    "    is_distributed=False,\n",
    "):\n",
    "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    pad_idx = vocab_tgt[\"<blank>\"]\n",
    "    d_model = 512\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.cuda(gpu)\n",
    "    module = model\n",
    "    is_main_process = True\n",
    "    if is_distributed:\n",
    "        dist.init_process_group(\n",
    "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
    "        )\n",
    "        model = DDP(model, device_ids=[gpu])\n",
    "        module = model.module\n",
    "        is_main_process = gpu == 0\n",
    "\n",
    "    criterion = LabelSmoothing(\n",
    "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
    "    )\n",
    "    criterion.cuda(gpu)\n",
    "\n",
    "    train_dataloader, valid_dataloader = create_dataloaders(\n",
    "        gpu,\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
    "        max_padding=config[\"max_padding\"],\n",
    "        is_distributed=is_distributed,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
    "        ),\n",
    "    )\n",
    "    train_state = TrainState()\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        if is_distributed:\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "            valid_dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        model.train()\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
    "        _, train_state = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train+log\",\n",
    "            accum_iter=config[\"accum_iter\"],\n",
    "            train_state=train_state,\n",
    "        )\n",
    "\n",
    "        GPUtil.showUtilization()\n",
    "        if is_main_process:\n",
    "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
    "            torch.save(module.state_dict(), file_path)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
    "        model.eval()\n",
    "        sloss = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )\n",
    "        print(sloss)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if is_main_process:\n",
    "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
    "        torch.save(module.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "\n",
    "    ngpus = torch.cuda.device_count()\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
    "    print(f\"Number of GPUs detected: {ngpus}\")\n",
    "    print(\"Spawning training processes ...\")\n",
    "    mp.spawn(\n",
    "        train_worker,\n",
    "        nprocs=ngpus,\n",
    "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    if config[\"distributed\"]:\n",
    "        train_distributed_model(\n",
    "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
    "        )\n",
    "    else:\n",
    "        train_worker(\n",
    "            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n",
    "        )\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"distributed\": False,\n",
    "        \"num_epochs\": 100,\n",
    "        \"accum_iter\": 10,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 72,\n",
    "        \"warmup\": 3000,\n",
    "        \"file_prefix\": \"multi30k_model_\",\n",
    "    }\n",
    "    model_path = \"multi30k_model_final.pt\"\n",
    "    if not exists(model_path):\n",
    "        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train worker process using GPU: 0 for training\n",
      "[GPU0] Epoch 0 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 0 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 1 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 1 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 2 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 2 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 3 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 3 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 4 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 4 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 5 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 5 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 6 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 6 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 7 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 7 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 8 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 8 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 9 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 9 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 10 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 10 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 11 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 11 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 12 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 12 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 13 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 13 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 14 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 14 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 15 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 15 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 16 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 16 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 17 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 17 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 18 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 18 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 19 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 19 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 20 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 20 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 21 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 21 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 22 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 22 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 23 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 23 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 24 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 24 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 25 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 25 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 26 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 26 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 27 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 27 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 28 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 28 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 29 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 29 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 30 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 90% |\n",
      "[GPU0] Epoch 30 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 31 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 90% |\n",
      "[GPU0] Epoch 31 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 32 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 90% |\n",
      "[GPU0] Epoch 32 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 33 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 33 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 34 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 34 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 35 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 35 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 36 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 36 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 37 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 37 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 38 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 38 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 39 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 39 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 40 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 40 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 41 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 41 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 42 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 42 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 43 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 91% |\n",
      "[GPU0] Epoch 43 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 44 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 44 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 45 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 45 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 46 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 46 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 47 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 47 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 48 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 91% |\n",
      "[GPU0] Epoch 48 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 49 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 91% |\n",
      "[GPU0] Epoch 49 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 50 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 91% |\n",
      "[GPU0] Epoch 50 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 51 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 51 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 52 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 52 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 53 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 53 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 54 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 54 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 55 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 55 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 56 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 90% |\n",
      "[GPU0] Epoch 56 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 57 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 57 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 58 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 58 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 59 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 59 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 60 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 60 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 61 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 61 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 62 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 62 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 63 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 90% |\n",
      "[GPU0] Epoch 63 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 64 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 64 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 65 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 65 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 66 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 66 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 67 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 67 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 68 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 68 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 69 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 69 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 70 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 90% |\n",
      "[GPU0] Epoch 70 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 71 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 90% |\n",
      "[GPU0] Epoch 71 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 72 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 72 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 73 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 73 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 74 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 91% |\n",
      "[GPU0] Epoch 74 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 75 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 75 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 76 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 76 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 77 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 90% |\n",
      "[GPU0] Epoch 77 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 78 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 91% |\n",
      "[GPU0] Epoch 78 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 79 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 79 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 80 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 93% |\n",
      "[GPU0] Epoch 80 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 81 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 81 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 82 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 92% |\n",
      "[GPU0] Epoch 82 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 83 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 83 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 84 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 84 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 85 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 85 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 86 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 86 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 87 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 92% |\n",
      "[GPU0] Epoch 87 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 88 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 88 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 89 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 92% |\n",
      "[GPU0] Epoch 89 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 90 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 90 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 91 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 92% |\n",
      "[GPU0] Epoch 91 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 92 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 92 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 93 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 93 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 94 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 92% |\n",
      "[GPU0] Epoch 94 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 95 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 95 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 96 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 91% |\n",
      "[GPU0] Epoch 96 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 97 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 97 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 98 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 90% |\n",
      "[GPU0] Epoch 98 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n",
      "[GPU0] Epoch 99 Training ====\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "[GPU0] Epoch 99 Validation ====\n",
      "(tensor(7.5726, device='cuda:0'), <transformer.training.TrainState object at 0x7f1ce5f53880>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(8315, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(6384, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=6384, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outputs(\n",
    "    valid_dataloader,\n",
    "    model,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    n_examples=15,\n",
    "    pad_idx=2,\n",
    "    eos_string=\"</s>\",\n",
    "):\n",
    "    results = [()] * n_examples\n",
    "    for idx in range(n_examples):\n",
    "        print(\"\\nExample %d ========\\n\" % idx)\n",
    "        b = next(iter(valid_dataloader))\n",
    "        rb = Batch(b[0], b[1], pad_idx)\n",
    "        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
    "\n",
    "        src_tokens = [\n",
    "            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
    "        ]\n",
    "        tgt_tokens = [\n",
    "            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            \"Source Text (Input)        : \"\n",
    "            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        print(\n",
    "            \"Target Text (Ground Truth) : \"\n",
    "            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
    "        model_txt = (\n",
    "            \" \".join(\n",
    "                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
    "            ).split(eos_string, 1)[0]\n",
    "            + eos_string\n",
    "        )\n",
    "        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n",
    "        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_model_example(n_examples=5):\n",
    "    global vocab_src, vocab_tgt, spacy_de, spacy_en\n",
    "\n",
    "    print(\"Preparing Data ...\")\n",
    "    _, valid_dataloader = create_dataloaders(\n",
    "        torch.device(\"cpu\"),\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=1,\n",
    "        is_distributed=False,\n",
    "    )\n",
    "\n",
    "    print(\"Loading Trained Model ...\")\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n",
    "    )\n",
    "\n",
    "    print(\"Checking Model Outputs:\")\n",
    "    example_data = check_outputs(\n",
    "        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n",
    "    )\n",
    "    return model, example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data ...\n",
      "Loading Trained Model ...\n",
      "Checking Model Outputs:\n",
      "\n",
      "Example 0 ========\n",
      "\n",
      "Source Text (Input)        : <s> Eine Gruppe von Polizisten steht vor einem Bus . </s>\n",
      "Target Text (Ground Truth) : <s> A bunch of police officers are standing outside a bus . </s>\n",
      "Model Output               : <s> fenced many floats lovers shake fenced hiding Good fenced many fenced cute Good fenced cute vegetables cute Good Good Good lei irritated fenced shop Tye fenced Good shop hat fenced stretch starting shop produce sipping Tye Road Good fenced skateboarder desert somebody lei Teenagers shop rinsing shop shop silk crow handrails rinsing Tye Tye irritated blading girl sipping objects silk kickboxing silk Firefighters stretch irritated learning tutu Firefighters Firefighters fenced Good</s>\n",
      "\n",
      "Example 1 ========\n",
      "\n",
      "Source Text (Input)        : <s> Ein kleiner Junge trägt eine <unk> Flagge und geht neben einer Frau . </s>\n",
      "Target Text (Ground Truth) : <s> A young boy carries a green , white , and red flag and walks next to a woman . </s>\n",
      "Model Output               : <s> club spinner club club club silk club rinsing club tossed club girl handrails spinner club streetlights spinner tossed rinsing spinner spinner tossed rinsing club fenced tossed club spinner spinner club club spinner spinner club spinner club club peering club fenced shop club shop spinner rinsing rinsing rinsing slope spinner Parents spinner rinsing tossed club tossed club Hikers spinner spinner club tossed club club club tossed rinsing tossed Firefighters club club plays</s>\n",
      "\n",
      "Example 2 ========\n",
      "\n",
      "Source Text (Input)        : <s> Die Frau bringt eine orange <unk> als <unk> am <unk> des Mannes an . </s>\n",
      "Target Text (Ground Truth) : <s> The woman is placing an orange rose as a <unk> on the man 's suit jacket collar . </s>\n",
      "Model Output               : <s> crow learning fenced radio Tye learning star learning sipping rinsing logo fenced peering rinsing cry hairy Teenagers rinsing kitchen Good tutu skateboarder rinsing learning fenced irritated fenced peering fenced plays stretch rinsing kitchen fenced brushes fenced spinner fenced desert peering plays handrails fenced Teenagers peering tossed pregnant shop swept handrails brushes peering cry might handrails brushes sound handrails brushes star handrails brushes Teenagers learning rinsing States rinsing fenced shop fenced fenced</s>\n",
      "\n",
      "Example 3 ========\n",
      "\n",
      "Source Text (Input)        : <s> Ein Typ mit einem leuchtend grünen Kapuzenpullover überquert einen Fußgängerüberweg , während er zu einem Unfall zwischen ein paar Autos und einem Fahrrad blickt . </s>\n",
      "Target Text (Ground Truth) : <s> A guy in a bright green hoodie is crossing a crosswalk while looking at an accident between some cars and a bike . </s>\n",
      "Model Output               : <s> inner desert wheelbarrows vocalist fenced fenced cry fenced fenced fenced holding explorer rod fenced spinner girl explorer spinner rod rinsing spinner spinner rinsing rinsing rinsing fenced spinner spinner fenced cry casting hairy skateboarder plays spinner skateboarder spinner casting tossed twigs rinsing spinner rinsing desert peering rinsing explorer peering process rinsing inner handrails explorer tossed might addresses handrails might fenced spinner spinner rinsing tossed rod fenced fenced silk cry fenced spinner fenced</s>\n",
      "\n",
      "Example 4 ========\n",
      "\n",
      "Source Text (Input)        : <s> Eine Reinigungskraft ist im Begriff , eine Bahnstation zu wischen . </s>\n",
      "Target Text (Ground Truth) : <s> A janitor about to mop in a train station . </s>\n",
      "Model Output               : <s> rinsing spinner rinsing Firefighters Good club Good learning spinner girl Good Firefighters radio feeding learning Good Good scooping rinsing rinsing Good club Good rinsing rinsing handrails Firefighters Firefighters Firefighters Firefighters spinner Good spinner rinsing feeding rinsing fenced Good Good rinsing rinsing shop inner Firefighters Firefighters rinsing rinsing kitchen learning middle club peering Good Firefighters sound rinsing rinsing kitchen rinsing Hikers uncompleted Firefighters Firefighters kitchen club rinsing rinsing rinsing kitchen club Firefighters</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(EncoderDecoder(\n",
       "   (encoder): Encoder(\n",
       "     (layers): ModuleList(\n",
       "       (0): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): EncoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): LayerNorm()\n",
       "   )\n",
       "   (decoder): Decoder(\n",
       "     (layers): ModuleList(\n",
       "       (0): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): DecoderLayer(\n",
       "         (self_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (src_attn): MultiHeadedAttention(\n",
       "           (linears): ModuleList(\n",
       "             (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "           )\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (feed_forward): PositionwiseFeedForward(\n",
       "           (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (sublayer): ModuleList(\n",
       "           (0): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (1): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (2): SublayerConnection(\n",
       "             (norm): LayerNorm()\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): LayerNorm()\n",
       "   )\n",
       "   (src_embed): Sequential(\n",
       "     (0): Embeddings(\n",
       "       (lut): Embedding(8315, 512)\n",
       "     )\n",
       "     (1): PositionalEncoding(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (tgt_embed): Sequential(\n",
       "     (0): Embeddings(\n",
       "       (lut): Embedding(6384, 512)\n",
       "     )\n",
       "     (1): PositionalEncoding(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (generator): Generator(\n",
       "     (proj): Linear(in_features=512, out_features=6384, bias=True)\n",
       "   )\n",
       " ),\n",
       " [(<transformer.training.Batch at 0x7f1c674ae7d0>,\n",
       "   ['<s>',\n",
       "    'Eine',\n",
       "    'Gruppe',\n",
       "    'von',\n",
       "    'Polizisten',\n",
       "    'steht',\n",
       "    'vor',\n",
       "    'einem',\n",
       "    'Bus',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'bunch',\n",
       "    'of',\n",
       "    'police',\n",
       "    'officers',\n",
       "    'are',\n",
       "    'standing',\n",
       "    'outside',\n",
       "    'a',\n",
       "    'bus',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([   0, 1065,  335, 1895, 4508, 4699, 1065, 2007, 4099, 1065,  335, 1065,\n",
       "           1991, 4099, 1065, 1991,  654, 1991, 4099, 4099, 4099, 4494, 5706, 1065,\n",
       "            329, 4152, 1065, 4099,  329,   70, 1065, 3438, 1606,  329,  923, 4712,\n",
       "           4152, 5050, 4099, 1065,  571,  848, 4730, 4494, 4148,  329, 6031,  329,\n",
       "            329, 6120, 5399, 5627, 6031, 4152, 4152, 5706, 5228,   33, 4712, 1523,\n",
       "           6120, 3288, 6120, 2378, 3438, 5706, 1733, 2554, 2378, 2378, 1065, 4099]),\n",
       "   '<s> fenced many floats lovers shake fenced hiding Good fenced many fenced cute Good fenced cute vegetables cute Good Good Good lei irritated fenced shop Tye fenced Good shop hat fenced stretch starting shop produce sipping Tye Road Good fenced skateboarder desert somebody lei Teenagers shop rinsing shop shop silk crow handrails rinsing Tye Tye irritated blading girl sipping objects silk kickboxing silk Firefighters stretch irritated learning tutu Firefighters Firefighters fenced Good</s>'),\n",
       "  (<transformer.training.Batch at 0x7f1c635fbfa0>,\n",
       "   ['<s>',\n",
       "    'Ein',\n",
       "    'kleiner',\n",
       "    'Junge',\n",
       "    'trägt',\n",
       "    'eine',\n",
       "    '<unk>',\n",
       "    'Flagge',\n",
       "    'und',\n",
       "    'geht',\n",
       "    'neben',\n",
       "    'einer',\n",
       "    'Frau',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'young',\n",
       "    'boy',\n",
       "    'carries',\n",
       "    'a',\n",
       "    'green',\n",
       "    ',',\n",
       "    'white',\n",
       "    ',',\n",
       "    'and',\n",
       "    'red',\n",
       "    'flag',\n",
       "    'and',\n",
       "    'walks',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'woman',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([   0, 1147, 4739, 1147, 1147, 1147, 6120, 1147, 6031, 1147, 3463, 1147,\n",
       "             33, 5627, 4739, 1147, 4761, 4739, 3463, 6031, 4739, 4739, 3463, 6031,\n",
       "           1147, 1065, 3463, 1147, 4739, 4739, 1147, 1147, 4739, 4739, 1147, 4739,\n",
       "           1147, 1147, 1595, 1147, 1065,  329, 1147,  329, 4739, 6031, 6031, 6031,\n",
       "            979, 4739, 3107, 4739, 6031, 3463, 1147, 3463, 1147, 4102, 4739, 4739,\n",
       "           1147, 3463, 1147, 1147, 1147, 3463, 6031, 3463, 2378, 1147, 1147,  138]),\n",
       "   '<s> club spinner club club club silk club rinsing club tossed club girl handrails spinner club streetlights spinner tossed rinsing spinner spinner tossed rinsing club fenced tossed club spinner spinner club club spinner spinner club spinner club club peering club fenced shop club shop spinner rinsing rinsing rinsing slope spinner Parents spinner rinsing tossed club tossed club Hikers spinner spinner club tossed club club club tossed rinsing tossed Firefighters club club plays</s>'),\n",
       "  (<transformer.training.Batch at 0x7f1c635fbee0>,\n",
       "   ['<s>',\n",
       "    'Die',\n",
       "    'Frau',\n",
       "    'bringt',\n",
       "    'eine',\n",
       "    'orange',\n",
       "    '<unk>',\n",
       "    'als',\n",
       "    '<unk>',\n",
       "    'am',\n",
       "    '<unk>',\n",
       "    'des',\n",
       "    'Mannes',\n",
       "    'an',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'The',\n",
       "    'woman',\n",
       "    'is',\n",
       "    'placing',\n",
       "    'an',\n",
       "    'orange',\n",
       "    'rose',\n",
       "    'as',\n",
       "    'a',\n",
       "    '<unk>',\n",
       "    'on',\n",
       "    'the',\n",
       "    'man',\n",
       "    \"'s\",\n",
       "    'suit',\n",
       "    'jacket',\n",
       "    'collar',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([   0, 5399, 1733, 1065, 2745, 4152, 1733, 1839, 1733, 4712, 6031, 2709,\n",
       "           1065, 1595, 6031, 4295, 5616, 4148, 6031,  291, 4099, 2554,  571, 6031,\n",
       "           1733, 1065, 5706, 1065, 1595, 1065,  138, 3438, 6031,  291, 1065, 2102,\n",
       "           1065, 4739, 1065,  848, 1595,  138, 5627, 1065, 4148, 1595, 3463, 4614,\n",
       "            329, 6244, 5627, 2102, 1595, 4295, 4531, 5627, 2102, 3427, 5627, 2102,\n",
       "           1839, 5627, 2102, 4148, 1733, 6031, 5077, 6031, 1065,  329, 1065, 1065]),\n",
       "   '<s> crow learning fenced radio Tye learning star learning sipping rinsing logo fenced peering rinsing cry hairy Teenagers rinsing kitchen Good tutu skateboarder rinsing learning fenced irritated fenced peering fenced plays stretch rinsing kitchen fenced brushes fenced spinner fenced desert peering plays handrails fenced Teenagers peering tossed pregnant shop swept handrails brushes peering cry might handrails brushes sound handrails brushes star handrails brushes Teenagers learning rinsing States rinsing fenced shop fenced fenced</s>'),\n",
       "  (<transformer.training.Batch at 0x7f1c635fbf40>,\n",
       "   ['<s>',\n",
       "    'Ein',\n",
       "    'Typ',\n",
       "    'mit',\n",
       "    'einem',\n",
       "    'leuchtend',\n",
       "    'grünen',\n",
       "    'Kapuzenpullover',\n",
       "    'überquert',\n",
       "    'einen',\n",
       "    'Fußgängerüberweg',\n",
       "    ',',\n",
       "    'während',\n",
       "    'er',\n",
       "    'zu',\n",
       "    'einem',\n",
       "    'Unfall',\n",
       "    'zwischen',\n",
       "    'ein',\n",
       "    'paar',\n",
       "    'Autos',\n",
       "    'und',\n",
       "    'einem',\n",
       "    'Fahrrad',\n",
       "    'blickt',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'guy',\n",
       "    'in',\n",
       "    'a',\n",
       "    'bright',\n",
       "    'green',\n",
       "    'hoodie',\n",
       "    'is',\n",
       "    'crossing',\n",
       "    'a',\n",
       "    'crosswalk',\n",
       "    'while',\n",
       "    'looking',\n",
       "    'at',\n",
       "    'an',\n",
       "    'accident',\n",
       "    'between',\n",
       "    'some',\n",
       "    'cars',\n",
       "    'and',\n",
       "    'a',\n",
       "    'bike',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([   0, 4456,  848, 6360, 3480, 1065, 1065, 4295, 1065, 1065, 1065,   46,\n",
       "           4356, 2044, 1065, 4739,   33, 4356, 4739, 2044, 6031, 4739, 4739, 6031,\n",
       "           6031, 6031, 1065, 4739, 4739, 1065, 4295, 2630, 5616,  571,  138, 4739,\n",
       "            571, 4739, 2630, 3463, 4825, 6031, 4739, 6031,  848, 1595, 6031, 4356,\n",
       "           1595, 2184, 6031, 4456, 5627, 4356, 3463, 4531, 4160, 5627, 4531, 1065,\n",
       "           4739, 4739, 6031, 3463, 2044, 1065, 1065, 6120, 4295, 1065, 4739, 1065]),\n",
       "   '<s> inner desert wheelbarrows vocalist fenced fenced cry fenced fenced fenced holding explorer rod fenced spinner girl explorer spinner rod rinsing spinner spinner rinsing rinsing rinsing fenced spinner spinner fenced cry casting hairy skateboarder plays spinner skateboarder spinner casting tossed twigs rinsing spinner rinsing desert peering rinsing explorer peering process rinsing inner handrails explorer tossed might addresses handrails might fenced spinner spinner rinsing tossed rod fenced fenced silk cry fenced spinner fenced</s>'),\n",
       "  (<transformer.training.Batch at 0x7f1c635fbdf0>,\n",
       "   ['<s>',\n",
       "    'Eine',\n",
       "    'Reinigungskraft',\n",
       "    'ist',\n",
       "    'im',\n",
       "    'Begriff',\n",
       "    ',',\n",
       "    'eine',\n",
       "    'Bahnstation',\n",
       "    'zu',\n",
       "    'wischen',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   ['<s>',\n",
       "    'A',\n",
       "    'janitor',\n",
       "    'about',\n",
       "    'to',\n",
       "    'mop',\n",
       "    'in',\n",
       "    'a',\n",
       "    'train',\n",
       "    'station',\n",
       "    '.',\n",
       "    '</s>'],\n",
       "   tensor([   0, 6031, 4739, 6031, 2378, 4099, 1147, 4099, 1733, 4739,   33, 4099,\n",
       "           2378, 2745, 1317, 1733, 4099, 4099, 3030, 6031, 6031, 4099, 1147, 4099,\n",
       "           6031, 6031, 5627, 2378, 2378, 2378, 2378, 4739, 4099, 4739, 6031, 1317,\n",
       "           6031, 1065, 4099, 4099, 6031, 6031,  329, 4456, 2378, 2378, 6031, 6031,\n",
       "            291, 1733,  181, 1147, 1595, 4099, 2378, 3427, 6031, 6031,  291, 6031,\n",
       "           4102, 4827, 2378, 2378,  291, 1147, 6031, 6031, 6031,  291, 1147, 2378]),\n",
       "   '<s> rinsing spinner rinsing Firefighters Good club Good learning spinner girl Good Firefighters radio feeding learning Good Good scooping rinsing rinsing Good club Good rinsing rinsing handrails Firefighters Firefighters Firefighters Firefighters spinner Good spinner rinsing feeding rinsing fenced Good Good rinsing rinsing shop inner Firefighters Firefighters rinsing rinsing kitchen learning middle club peering Good Firefighters sound rinsing rinsing kitchen rinsing Hikers uncompleted Firefighters Firefighters kitchen club rinsing rinsing rinsing kitchen club Firefighters</s>')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3878d7a7a447c7cc89f75f8ff38bbdbae1c418e3499f30fae1ec67e71de8e5b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
